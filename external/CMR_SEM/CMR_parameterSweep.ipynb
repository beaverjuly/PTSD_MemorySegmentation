{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMR Model: Parameter Sweep Analysis\n",
    "\n",
    "This notebook implements parameter sweeps for the **Context Maintenance and Retrieval (CMR)** model of episodic memory.\n",
    "\n",
    "## Model Overview\n",
    "- **Episodic associations**: Learned item-context connections during encoding\n",
    "- **Semantic associations**: Pre-existing meaning-based item connections\n",
    "- **Context drift**: Gradual change in temporal context during encoding/retrieval\n",
    "\n",
    "## Notebook Structure\n",
    "1. Setup & Parameters\n",
    "2. Core Simulation Functions (reusable)\n",
    "3. Analysis Metrics (reusable)\n",
    "4. Visualization Functions (reusable)\n",
    "5. Parameter Sweep Execution\n",
    "6. Results Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Model Parameters\n",
    "\n",
    "### List Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List length and presentation order\n",
    "N = 10\n",
    "pres_indices = np.random.permutation(N) + 1  # 1-indexed presentation order\n",
    "\n",
    "# Sequence values (not used in basic CMR, but kept for compatibility)\n",
    "sequence = np.array([50, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Route Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance between semantic and episodic retrieval routes\n",
    "sem = 0.5\n",
    "episodic = 0.5\n",
    "\n",
    "# Normalize to sum to 1\n",
    "sem_weight = sem / (episodic + sem)\n",
    "episodic_weight = episodic / (episodic + sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Drift Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding drift: how much context changes when each item is presented\n",
    "# First item causes complete context update; subsequent items cause moderate drift\n",
    "B_encD = np.array([1.0, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65])\n",
    "\n",
    "# Base encoding rate (not used when B_encD is specified, but kept for reference)\n",
    "B_enc = 0.745"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orthogonal semantic representation (each item is distinct)\n",
    "sem_mat = np.eye(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Architecture Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-existing connection strengths\n",
    "gamma_fc = 0.581  # Strength of pre-existing feature-context associations\n",
    "eye_fc = 1 - gamma_fc\n",
    "eye_cf = 0\n",
    "\n",
    "# Learning rates during encoding\n",
    "lrate_fc_enc = gamma_fc  # Feature-to-context learning rate\n",
    "lrate_cf_enc = 1.0       # Context-to-feature learning rate\n",
    "\n",
    "# Learning rates during retrieval (typically 0 - no new learning)\n",
    "lrate_fc_rec = 0.0\n",
    "lrate_cf_rec = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval Dynamics Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulator dynamics (Leaky Competing Accumulator model)\n",
    "thresh = 1.0         # Threshold for successful retrieval\n",
    "rec_time = 90000     # Maximum recall period (ms)\n",
    "dt = 100             # Time step (ms)\n",
    "tau = 413            # Time constant for accumulation\n",
    "K = 0.091            # Decay rate\n",
    "L = 0.375            # Lateral inhibition strength\n",
    "eta = 0.3699         # Noise standard deviation\n",
    "\n",
    "# Number of simulations for averaging\n",
    "n_sims = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Core Simulation Functions\n",
    "\n",
    "These functions are designed to be **reusable** for different parameter sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_single_trial(B_rec, rng, record_diagnostics=False):\n",
    "    \"\"\"\n",
    "    Simulate one encoding-retrieval trial.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    B_rec : float\n",
    "        Context drift rate during retrieval\n",
    "    rng : numpy.random.Generator\n",
    "        Random number generator for reproducibility\n",
    "    record_diagnostics : bool\n",
    "        If True, record cue advantage diagnostics\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    recalls : array (N,)\n",
    "        Serial positions recalled (1-indexed, 0 = no recall)\n",
    "    times : array (N,)\n",
    "        Retrieval times for each recall\n",
    "    net_w_fc : array (N, N)\n",
    "        Feature-to-context weight matrix after encoding\n",
    "    net_w_cf : array (N, N)\n",
    "        Context-to-feature weight matrix after encoding\n",
    "    diagnostics : dict or None\n",
    "        Cue advantage measurements (if record_diagnostics=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ========== INITIALIZATION ==========\n",
    "    net_f = np.zeros((N, 1))  # Feature layer activations\n",
    "    net_c = np.zeros((N, 1))  # Context layer activations\n",
    "    \n",
    "    # Initialize weight matrices\n",
    "    net_w_fc = np.eye(N) * eye_fc\n",
    "    net_w_cf = np.eye(N) * eye_cf\n",
    "    \n",
    "    # ========== ENCODING PHASE ==========\n",
    "    for item_idx in range(N):\n",
    "        # Get the item to present (0-indexed)\n",
    "        feature_idx = pres_indices[item_idx] - 1\n",
    "        \n",
    "        # Activate current item in feature layer\n",
    "        net_f = np.zeros((N, 1))\n",
    "        net_f[feature_idx] = 1\n",
    "        \n",
    "        # Compute context input from features\n",
    "        net_c_in = net_w_fc @ net_f\n",
    "        net_c_in = net_c_in / float(np.sqrt(net_c_in.T @ net_c_in))  # Normalize\n",
    "        \n",
    "        # Update context using drift dynamics\n",
    "        c_in, c = net_c_in, net_c\n",
    "        B = B_encD[item_idx]  # Context drift for this item\n",
    "        dot = float(c.T @ c_in)\n",
    "        rho = np.sqrt(1 + (B**2) * ((dot**2) - 1)) - B * dot\n",
    "        net_c = rho * c + B * c_in\n",
    "        \n",
    "        # Update associative weights (Hebbian learning)\n",
    "        net_w_fc += (net_c @ net_f.T) * lrate_fc_enc\n",
    "        net_w_cf += (net_f @ net_c.T) * lrate_cf_enc\n",
    "    \n",
    "    # ========== RETRIEVAL SETUP ==========\n",
    "    recalls = np.zeros((N, 1))\n",
    "    times = np.zeros((N, 1))\n",
    "    retrieved = np.zeros((N, 1), dtype=bool)\n",
    "    thresholds = np.ones((N, 1))\n",
    "    \n",
    "    # Combined retrieval cue (episodic + semantic routes)\n",
    "    net_weights = episodic_weight * net_w_cf + sem_weight * sem_mat\n",
    "    \n",
    "    time_passed = 0\n",
    "    recall_count = 0\n",
    "    \n",
    "    # Diagnostic tracking (optional)\n",
    "    if record_diagnostics:\n",
    "        deltas_all = []\n",
    "        deltas_by_pos = defaultdict(list)\n",
    "        delta_forward = []\n",
    "        delta_backward = []\n",
    "        pending = None\n",
    "    \n",
    "    # ========== RETRIEVAL LOOP ==========\n",
    "    while time_passed < rec_time:\n",
    "        \n",
    "        # Compute feature input from current context\n",
    "        f_in = net_weights @ net_c\n",
    "        \n",
    "        # Setup accumulator simulation\n",
    "        max_cycles = int((rec_time - time_passed) / dt)\n",
    "        dt_tau = dt / tau\n",
    "        sq_dt_tau = np.sqrt(dt_tau)\n",
    "        \n",
    "        # Pre-generate noise for all cycles\n",
    "        noise = rng.normal(0, eta * sq_dt_tau, size=(N, max_cycles))\n",
    "        \n",
    "        # Lateral inhibition matrix (inhibit all except self)\n",
    "        eyeI = ~np.eye(N, dtype=bool)\n",
    "        lmat = eyeI.astype(float) * L\n",
    "        \n",
    "        # Initialize accumulators\n",
    "        x = np.zeros((N, 1))\n",
    "        K_array = np.ones((N, 1)) * K\n",
    "        inds = np.arange(N)\n",
    "        \n",
    "        crossed = 0\n",
    "        i = 0\n",
    "        \n",
    "        # Run accumulator dynamics until threshold crossed or time runs out\n",
    "        while i < max_cycles and crossed == 0:\n",
    "            \n",
    "            # Compute inhibition and decay\n",
    "            lx = lmat @ x\n",
    "            kx = K_array * x\n",
    "            \n",
    "            # Update accumulator activations\n",
    "            x = x + ((f_in - kx - lx) * dt_tau + noise[:, i:i+1])\n",
    "            x[x < 0] = 0  # No negative activations\n",
    "            \n",
    "            # Reset previously retrieved items (prevent repetitions)\n",
    "            reset_these = retrieved & (x >= thresholds)\n",
    "            x[reset_these] = 0.95 * thresholds[reset_these]\n",
    "            \n",
    "            # Check for threshold crossing\n",
    "            retrievable = ~retrieved\n",
    "            if np.any(x[retrievable] >= thresholds[retrievable]):\n",
    "                crossed = 1\n",
    "                temp_win = x[retrievable] >= thresholds[retrievable]\n",
    "                temp_ind = inds[retrievable.flatten()]\n",
    "                winners = temp_ind[temp_win.flatten()]\n",
    "                \n",
    "                # Random tiebreaker if multiple items cross simultaneously\n",
    "                if len(winners) > 1:\n",
    "                    winners = np.array([rng.choice(winners)])\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        time_passed += i * dt\n",
    "        \n",
    "        # ========== PROCESS RETRIEVAL ==========\n",
    "        if crossed == 1:\n",
    "            winner = int(winners[0])\n",
    "            \n",
    "            # Find serial position of retrieved item\n",
    "            serial_pos0 = np.where(pres_indices - 1 == winner)[0][0]\n",
    "            serial_pos1 = serial_pos0 + 1  # 1-indexed\n",
    "            \n",
    "            # Record diagnostics if requested\n",
    "            if record_diagnostics and pending is not None:\n",
    "                prev_pos0 = pending[\"serial_pos0\"]\n",
    "                delta_f_prev = pending[\"delta_f\"]\n",
    "                transition = serial_pos0 - prev_pos0\n",
    "                \n",
    "                if transition == 1:\n",
    "                    delta_forward.append(delta_f_prev)\n",
    "                elif transition == -1:\n",
    "                    delta_backward.append(delta_f_prev)\n",
    "                \n",
    "                pending = None\n",
    "            \n",
    "            # Reactivate retrieved item\n",
    "            net_f = np.zeros((N, 1))\n",
    "            net_f[winner] = 1\n",
    "            \n",
    "            # Update context based on retrieved item\n",
    "            net_c_in = net_w_fc @ net_f\n",
    "            net_c_in = net_c_in / float(np.sqrt(net_c_in.T @ net_c_in))\n",
    "            \n",
    "            c_in, c = net_c_in, net_c\n",
    "            dot = float(c.T @ c_in)\n",
    "            rho = np.sqrt(1 + (B_rec**2) * ((dot**2) - 1)) - B_rec * dot\n",
    "            net_c = rho * c + B_rec * c_in\n",
    "            \n",
    "            # Update weights (typically zero learning during retrieval)\n",
    "            net_w_fc += (net_c @ net_f.T) * lrate_fc_rec\n",
    "            net_w_cf += (net_f @ net_c.T) * lrate_cf_rec\n",
    "            \n",
    "            # Record recall\n",
    "            recall_count += 1\n",
    "            recalls[recall_count - 1, 0] = serial_pos1\n",
    "            times[recall_count - 1, 0] = time_passed\n",
    "            \n",
    "            # Compute cue advantage diagnostics if needed\n",
    "            if record_diagnostics:\n",
    "                left_pos0 = serial_pos0 - 1\n",
    "                right_pos0 = serial_pos0 + 1\n",
    "                \n",
    "                # Check if both neighbors are available\n",
    "                if 0 <= left_pos0 < N and 0 <= right_pos0 < N:\n",
    "                    left_item = pres_indices[left_pos0] - 1\n",
    "                    right_item = pres_indices[right_pos0] - 1\n",
    "                    \n",
    "                    if (not retrieved[left_item]) and (not retrieved[right_item]):\n",
    "                        f_after = (net_weights @ net_c).flatten()\n",
    "                        delta_f = f_after[right_item] - f_after[left_item]\n",
    "                        \n",
    "                        deltas_all.append(delta_f)\n",
    "                        deltas_by_pos[serial_pos1].append(delta_f)\n",
    "                        pending = {\"serial_pos0\": serial_pos0, \"delta_f\": delta_f}\n",
    "            \n",
    "            retrieved[winner] = True\n",
    "    \n",
    "    # Compile diagnostics\n",
    "    diagnostics = None\n",
    "    if record_diagnostics:\n",
    "        diagnostics = {\n",
    "            \"deltas_all\": deltas_all,\n",
    "            \"deltas_by_pos\": dict(deltas_by_pos),\n",
    "            \"delta_forward\": delta_forward,\n",
    "            \"delta_backward\": delta_backward\n",
    "        }\n",
    "    \n",
    "    return recalls.flatten(), times.flatten(), net_w_fc, net_w_cf, diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(B_rec, n_sims=1000, seed=2026):\n",
    "    \"\"\"\n",
    "    Run multiple independent trials with the same parameters.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    B_rec : float\n",
    "        Context drift rate during retrieval\n",
    "    n_sims : int\n",
    "        Number of independent simulations\n",
    "    seed : int\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    recall_sims : array (N, n_sims)\n",
    "        Recall sequences for all simulations\n",
    "    times_sims : array (N, n_sims)\n",
    "        Retrieval times for all simulations\n",
    "    net_w_fc : array (N, N)\n",
    "        Final feature-to-context weights (from last simulation)\n",
    "    net_w_cf : array (N, N)\n",
    "        Final context-to-feature weights (from last simulation)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    recall_sims = np.zeros((N, n_sims), dtype=int)\n",
    "    times_sims = np.zeros((N, n_sims), dtype=float)\n",
    "    \n",
    "    net_w_fc_last = None\n",
    "    net_w_cf_last = None\n",
    "    \n",
    "    for s in range(n_sims):\n",
    "        recalls, times, net_w_fc, net_w_cf, _ = simulate_single_trial(\n",
    "            B_rec=B_rec,\n",
    "            rng=rng,\n",
    "            record_diagnostics=False\n",
    "        )\n",
    "        \n",
    "        recall_sims[:, s] = recalls.astype(int)\n",
    "        times_sims[:, s] = times\n",
    "        \n",
    "        net_w_fc_last = net_w_fc\n",
    "        net_w_cf_last = net_w_cf\n",
    "    \n",
    "    return recall_sims, times_sims, net_w_fc_last, net_w_cf_last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Analysis Metrics\n",
    "\n",
    "Functions to compute standard free recall measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spc(recall_sims, N):\n",
    "    \"\"\"\n",
    "    Compute Serial Position Curve.\n",
    "    \n",
    "    Measures P(recall) for each serial position.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    recall_sims : array (N, n_sims)\n",
    "        Recall sequences (serial positions 1-N, 0 = no recall)\n",
    "    N : int\n",
    "        List length\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    spc : array (N,)\n",
    "        Probability of recall for each position\n",
    "    \"\"\"\n",
    "    spc = np.zeros(N)\n",
    "    for j in range(1, N + 1):\n",
    "        spc[j - 1] = np.mean(np.any(recall_sims == j, axis=0))\n",
    "    return spc\n",
    "\n",
    "\n",
    "def compute_pfr(recall_sims, N):\n",
    "    \"\"\"\n",
    "    Compute Probability of First Recall.\n",
    "    \n",
    "    Measures P(first recall) for each serial position.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    recall_sims : array (N, n_sims)\n",
    "        Recall sequences\n",
    "    N : int\n",
    "        List length\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pfr : array (N,)\n",
    "        Probability of first recall for each position\n",
    "    \"\"\"\n",
    "    first = recall_sims[0, :]\n",
    "    first = first[first > 0]  # Remove trials with no recalls\n",
    "    \n",
    "    pfr = np.zeros(N)\n",
    "    if len(first) > 0:\n",
    "        for j in range(1, N + 1):\n",
    "            pfr[j - 1] = np.mean(first == j)\n",
    "    return pfr\n",
    "\n",
    "\n",
    "def compute_lag_crp(recall_sims, N):\n",
    "    \"\"\"\n",
    "    Compute opportunity-corrected Lag-CRP.\n",
    "    \n",
    "    Conditional Response Probability as a function of lag\n",
    "    (temporal distance between successive recalls).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    recall_sims : array (N, n_sims)\n",
    "        Recall sequences\n",
    "    N : int\n",
    "        List length\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lag_vals : array\n",
    "        Lag values (negative = backward, positive = forward)\n",
    "    crp : array\n",
    "        Conditional response probabilities for each lag\n",
    "    \"\"\"\n",
    "    max_lag = N - 1\n",
    "    lag_vals = np.arange(-max_lag, max_lag + 1)\n",
    "    \n",
    "    numer = np.zeros(len(lag_vals), dtype=float)  # Actual transitions\n",
    "    denom = np.zeros(len(lag_vals), dtype=float)  # Possible transitions\n",
    "    \n",
    "    lag_to_idx = {L: i for i, L in enumerate(lag_vals)}\n",
    "    \n",
    "    for s in range(recall_sims.shape[1]):\n",
    "        seq = recall_sims[:, s]\n",
    "        seq = seq[seq > 0].astype(int)  # Remove blanks\n",
    "        \n",
    "        if len(seq) < 2:\n",
    "            continue\n",
    "        \n",
    "        recalled = set()\n",
    "        \n",
    "        for t in range(len(seq) - 1):\n",
    "            cur = seq[t]\n",
    "            nxt = seq[t + 1]\n",
    "            \n",
    "            recalled.add(cur)\n",
    "            remaining = [j for j in range(1, N + 1) if j not in recalled]\n",
    "            \n",
    "            # Count all possible transitions from current position\n",
    "            for j in remaining:\n",
    "                L = j - cur\n",
    "                denom[lag_to_idx[L]] += 1\n",
    "            \n",
    "            # Count actual transition\n",
    "            L_obs = nxt - cur\n",
    "            numer[lag_to_idx[L_obs]] += 1\n",
    "    \n",
    "    # Compute conditional probabilities\n",
    "    crp = np.zeros_like(numer)\n",
    "    valid = denom > 0\n",
    "    crp[valid] = numer[valid] / denom[valid]\n",
    "    \n",
    "    return lag_vals, crp\n",
    "\n",
    "\n",
    "def compute_cue_diagnostics(B_rec, n_sims=100, seed=2026):\n",
    "    \"\"\"\n",
    "    Compute neighbor cue advantage diagnostics.\n",
    "    \n",
    "    Measures the difference in cue strength between forward (i+1)\n",
    "    and backward (i-1) neighbors after recalling position i.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    B_rec : float\n",
    "        Retrieval drift rate\n",
    "    n_sims : int\n",
    "        Number of simulations\n",
    "    seed : int\n",
    "        Random seed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    diagnostics : dict\n",
    "        Contains deltas_all, deltas_by_pos, delta_forward, delta_backward\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    deltas_all = []\n",
    "    deltas_by_pos = defaultdict(list)\n",
    "    delta_forward = []\n",
    "    delta_backward = []\n",
    "    \n",
    "    for s in range(n_sims):\n",
    "        _, _, _, _, diag = simulate_single_trial(\n",
    "            B_rec=B_rec,\n",
    "            rng=rng,\n",
    "            record_diagnostics=True\n",
    "        )\n",
    "        \n",
    "        deltas_all.extend(diag[\"deltas_all\"])\n",
    "        delta_forward.extend(diag[\"delta_forward\"])\n",
    "        delta_backward.extend(diag[\"delta_backward\"])\n",
    "        \n",
    "        for k, v in diag[\"deltas_by_pos\"].items():\n",
    "            deltas_by_pos[k].extend(v)\n",
    "    \n",
    "    return {\n",
    "        \"deltas_all\": deltas_all,\n",
    "        \"deltas_by_pos\": dict(deltas_by_pos),\n",
    "        \"delta_forward\": delta_forward,\n",
    "        \"delta_backward\": delta_backward\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Visualization Functions\n",
    "\n",
    "Reusable plotting functions for sweep results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spc_sweep(sweep_results, param_grid, param_name=\"Parameter\"):\n",
    "    \"\"\"\n",
    "    Plot Serial Position Curves across parameter values.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sweep_results : dict\n",
    "        Results dictionary from parameter sweep\n",
    "    param_grid : list\n",
    "        Parameter values tested\n",
    "    param_name : str\n",
    "        Name of parameter for legend\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    serial_labels = np.arange(1, N + 1)\n",
    "    \n",
    "    for param_val in param_grid:\n",
    "        spc = sweep_results[param_val][\"SPC\"]\n",
    "        plt.plot(serial_labels, spc, marker=\"o\", \n",
    "                label=f\"{param_name}={param_val:.2f}\")\n",
    "    \n",
    "    plt.title(f\"Serial Position Curve across {param_name}\")\n",
    "    plt.xlabel(\"Serial Position\")\n",
    "    plt.ylabel(\"P(Recall)\")\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_pfr_sweep(sweep_results, param_grid, param_name=\"Parameter\"):\n",
    "    \"\"\"\n",
    "    Plot Probability of First Recall across parameter values.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    serial_labels = np.arange(1, N + 1)\n",
    "    \n",
    "    for param_val in param_grid:\n",
    "        pfr = sweep_results[param_val][\"PFR\"]\n",
    "        plt.plot(serial_labels, pfr, marker=\"o\",\n",
    "                label=f\"{param_name}={param_val:.2f}\")\n",
    "    \n",
    "    plt.title(f\"Probability of First Recall across {param_name}\")\n",
    "    plt.xlabel(\"Serial Position\")\n",
    "    plt.ylabel(\"P(First Recall)\")\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_lag_crp_sweep(sweep_results, param_grid, param_name=\"Parameter\"):\n",
    "    \"\"\"\n",
    "    Plot Lag-CRP curves across parameter values.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    for param_val in param_grid:\n",
    "        recall_sims = sweep_results[param_val][\"recall_sims\"]\n",
    "        lag_vals, crp = compute_lag_crp(recall_sims, N)\n",
    "        \n",
    "        neg = lag_vals < 0\n",
    "        pos = lag_vals > 0\n",
    "        \n",
    "        # Plot negative lags\n",
    "        line, = plt.plot(lag_vals[neg], crp[neg], marker=\"o\",\n",
    "                        label=f\"{param_name}={param_val:.2f}\")\n",
    "        \n",
    "        # Plot positive lags with same color\n",
    "        plt.plot(lag_vals[pos], crp[pos], marker=\"o\", color=line.get_color())\n",
    "    \n",
    "    plt.axvline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.title(f\"Lag-CRP across {param_name}\")\n",
    "    plt.xlabel(\"Lag (next − current)\")\n",
    "    plt.ylabel(\"CRP(lag)\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_cue_advantage_by_position(sweep_results, param_grid, param_name=\"Parameter\"):\n",
    "    \"\"\"\n",
    "    Plot mean cue advantage [f(i+1) - f(i-1)] by serial position.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    positions = np.arange(1, N + 1)\n",
    "    \n",
    "    for param_val in param_grid:\n",
    "        diag = sweep_results[param_val][\"cue_diag\"]\n",
    "        \n",
    "        means = []\n",
    "        for p in positions:\n",
    "            vals = diag[\"deltas_by_pos\"].get(p, [])\n",
    "            means.append(np.mean(vals) if len(vals) > 0 else np.nan)\n",
    "        \n",
    "        plt.plot(positions, means, marker=\"o\",\n",
    "                label=f\"{param_name}={param_val:.2f}\")\n",
    "    \n",
    "    plt.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.title(f\"Cue Advantage by Position across {param_name}\")\n",
    "    plt.xlabel(\"Current Serial Position (i)\")\n",
    "    plt.ylabel(r\"Mean Cue Advantage: $f(i+1) - f(i-1)$\")\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_overall_cue_advantage(sweep_results, param_grid, param_name=\"Parameter\"):\n",
    "    \"\"\"\n",
    "    Plot overall mean cue advantage as a function of parameter value.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    \n",
    "    advantages = []\n",
    "    for param_val in param_grid:\n",
    "        diag = sweep_results[param_val][\"cue_diag\"]\n",
    "        adv = np.mean(diag[\"deltas_all\"]) if len(diag[\"deltas_all\"]) > 0 else np.nan\n",
    "        advantages.append(adv)\n",
    "    \n",
    "    plt.plot(param_grid, advantages, marker=\"o\", linewidth=2, markersize=8)\n",
    "    plt.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.title(f\"Overall Cue Advantage vs {param_name}\")\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(r\"Mean Cue Advantage: $f(i+1) - f(i-1)$\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Parameter Sweep: Retrieval Drift ($B_{rec}$)\n",
    "\n",
    "Sweep across different values of retrieval context drift to examine its effect on recall dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter values to test\n",
    "B_rec_grid = [0.10, 0.25, 0.40, 0.55, 0.70, 0.85]\n",
    "\n",
    "# Base seed for reproducibility (incremented for each parameter value)\n",
    "BASE_SEED = 2026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Parameter Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_results = {}\n",
    "\n",
    "print(\"Running parameter sweep...\")\n",
    "for idx, B_rec_val in enumerate(B_rec_grid):\n",
    "    print(f\"  B_rec = {B_rec_val:.2f} ({idx+1}/{len(B_rec_grid)})\")\n",
    "    \n",
    "    seed = BASE_SEED + idx\n",
    "    \n",
    "    # Run main simulation\n",
    "    recall_sims, times_sims, net_w_fc, net_w_cf = run_simulation(\n",
    "        B_rec=B_rec_val,\n",
    "        n_sims=n_sims,\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    # Compute metrics\n",
    "    spc = compute_spc(recall_sims, N)\n",
    "    pfr = compute_pfr(recall_sims, N)\n",
    "    lag_vals, lag_probs = compute_lag_crp(recall_sims, N)\n",
    "    \n",
    "    # Compute diagnostics (fewer simulations for speed)\n",
    "    diag = compute_cue_diagnostics(B_rec_val, n_sims=n_sims, seed=seed)\n",
    "    \n",
    "    # Store results\n",
    "    sweep_results[B_rec_val] = {\n",
    "        \"recall_sims\": recall_sims,\n",
    "        \"times_sims\": times_sims,\n",
    "        \"SPC\": spc,\n",
    "        \"PFR\": pfr,\n",
    "        \"lag_vals\": lag_vals,\n",
    "        \"lag_probs\": lag_probs,\n",
    "        \"net_w_fc\": net_w_fc,\n",
    "        \"net_w_cf\": net_w_cf,\n",
    "        \"cue_diag\": diag\n",
    "    }\n",
    "\n",
    "print(\"\\nSweep complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Visualize Results\n",
    "\n",
    "### Serial Position Curves\n",
    "\n",
    "Higher $B_{rec}$ → more context drift during retrieval → stronger recency effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spc_sweep(sweep_results, B_rec_grid, param_name=r\"$B_{rec}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability of First Recall\n",
    "\n",
    "Shows which items are most likely to initiate retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pfr_sweep(sweep_results, B_rec_grid, param_name=r\"$B_{rec}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lag-CRP (Temporal Contiguity)\n",
    "\n",
    "Measures tendency to recall items that were studied near each other in time.\n",
    "- **Positive lags**: Forward transitions (i → i+1)\n",
    "- **Negative lags**: Backward transitions (i → i-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lag_crp_sweep(sweep_results, B_rec_grid, param_name=r\"$B_{rec}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cue Advantage by Position\n",
    "\n",
    "After recalling position $i$, how much does the retrieval cue favor the forward neighbor $(i+1)$ vs backward neighbor $(i-1)$?\n",
    "\n",
    "Positive values → forward bias; Negative values → backward bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cue_advantage_by_position(sweep_results, B_rec_grid, param_name=r\"$B_{rec}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Cue Advantage\n",
    "\n",
    "Mean cue advantage across all positions as a function of $B_{rec}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_overall_cue_advantage(sweep_results, B_rec_grid, param_name=r\"$B_{rec}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "This notebook provides a **reusable framework** for parameter sweeps in the CMR model:\n",
    "\n",
    "1. **Modular simulation functions** - Easy to run with different parameters\n",
    "2. **Standard metrics** - SPC, PFR, Lag-CRP, cue diagnostics\n",
    "3. **Flexible visualization** - Can be applied to any parameter sweep\n",
    "\n",
    "### To run a different parameter sweep:\n",
    "\n",
    "1. Modify the parameter grid (e.g., sweep `B_enc`, `sem_weight`, `gamma_fc`)\n",
    "2. Update the parameter value in `run_simulation()` or `simulate_single_trial()`\n",
    "3. Use the same visualization functions\n",
    "\n",
    "### Example - sweeping encoding drift:\n",
    "\n",
    "```python\n",
    "# Define new parameter grid\n",
    "B_enc_grid = [0.3, 0.5, 0.7, 0.9]\n",
    "B_enc_results = {}\n",
    "\n",
    "# Modify simulation to use different B_encD values\n",
    "for B_enc_val in B_enc_grid:\n",
    "    # Update B_encD before running simulation\n",
    "    B_encD = np.full(N, B_enc_val)\n",
    "    B_encD[0] = 1.0  # Keep first item at full drift\n",
    "    \n",
    "    # Run simulation with fixed B_rec\n",
    "    recall_sims, _, _, _ = run_simulation(B_rec=0.36, n_sims=1000)\n",
    "    \n",
    "    # Compute and store metrics...\n",
    "\n",
    "# Visualize using the same functions\n",
    "plot_spc_sweep(B_enc_results, B_enc_grid, param_name=\"B_enc\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
