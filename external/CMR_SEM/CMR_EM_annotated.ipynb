{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Maintenance and Retrieval (CMR) Model\n",
    "\n",
    "This notebook implements the CMR model (Polyn, Norman & Kahana, 2009), a computational model of human episodic memory that explains how people recall lists of items. The model combines:\n",
    "\n",
    "- **Episodic associations**: Learned connections between items and the temporal context in which they were presented\n",
    "- **Semantic associations**: Pre-existing associations between items based on their meaning\n",
    "- **Context drift**: The gradual change in mental context over time during encoding and retrieval\n",
    "\n",
    "The model simulates classic memory phenomena including primacy effects (better recall of early items), recency effects (better recall of recent items), and temporal contiguity (tendency to recall items presented close together in time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters to Change\n",
    "\n",
    "These parameters control the relative strength of semantic versus episodic retrieval routes:\n",
    "\n",
    "- **sem**: Weight of semantic associations (meaning-based connections)\n",
    "- **episodic**: Weight of episodic associations (temporal context-based connections)\n",
    "\n",
    "The weights are normalized so they sum to 1, determining the relative contribution of each route during memory retrieval. Equal weights (0.5/0.5) mean both routes contribute equally to recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strength of drift\n",
    "# scale_drift = 0.4  # scaling parameter (not used if inputting manual drift)\n",
    "\n",
    "# strength of semantic + episodic route\n",
    "sem = 0.5\n",
    "episodic = 0.5\n",
    "\n",
    "# normalize\n",
    "sem_weight = sem / (episodic + sem)\n",
    "episodic_weight = episodic / (episodic + sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reward Sequence\n",
    "\n",
    "Defines the presentation order and values of items in the simulated memory list:\n",
    "\n",
    "- **pres_indices**: Random permutation determining the order items are presented\n",
    "- **sequence**: Reward values associated with each position (used to calculate prediction errors)\n",
    "\n",
    "The \"primacy\" sequence used here shows gradually decreasing values (54 → 45), which can affect context drift when prediction error-based drift is enabled. This simulates scenarios where reward or value changes over the course of a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sample (1-indexed to match R behavior, then convert to 0-indexed)\n",
    "pres_indices = np.random.permutation(10) + 1\n",
    "\n",
    "# high RPE within sequence (first outcome is \"reward expectation\" at 0)\n",
    "# sequence = np.array([0, 54, 57, 56, 53, 55, 7, 5, 4, 6, 3])  # initial expectation is 0\n",
    "\n",
    "# primacy (first outcome is \"reward expectation\" at 50)\n",
    "sequence = np.array([50, 54, 53, 52, 51, 50, 49, 48, 47, 46, 45])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Drift\n",
    "\n",
    "**Context drift** refers to how quickly the mental context changes during encoding. This section (currently commented out) implements dynamic drift based on prediction errors:\n",
    "\n",
    "**Logic**:\n",
    "1. Calculate absolute prediction errors (difference between consecutive rewards)\n",
    "2. Z-score normalize the prediction errors\n",
    "3. Scale by `scale_drift` parameter\n",
    "4. Cap maximum drift at 1.0\n",
    "\n",
    "**Interpretation**: Larger prediction errors cause greater context drift, meaning unexpected events create stronger temporal boundaries in memory. This can enhance memory for items around surprising events.\n",
    "\n",
    "This approach is currently disabled in favor of manual drift specification below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamic beta\n",
    "# absPE = np.zeros((len(pres_indices), 1))\n",
    "\n",
    "# take absolute difference of previous reward with current reward\n",
    "# (first \"prediction error\" is reward - initial expectation)\n",
    "# for seq in range(len(sequence) - 1):\n",
    "#     absPE[seq] = abs(sequence[seq] - sequence[seq + 1])\n",
    "\n",
    "# take absolute value of z-scored absPE and multiply by scaling parameter\n",
    "# B_encD = np.abs(zscore(absPE)) * scale_drift\n",
    "\n",
    "# B_encD = np.where(B_encD > 1, 1, B_encD)  # if it's over 1, make it 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Drift\n",
    "\n",
    "Manually specified context integration rates (β values) for each item during encoding:\n",
    "\n",
    "- **B_encD[0] = 1.0**: First item causes maximum context drift (complete context update)\n",
    "- **B_encD[1:] = 0.65**: Subsequent items cause moderate drift\n",
    "\n",
    "**Interpretation**: High drift for the first item creates a strong primacy effect - the first item becomes strongly associated with the initial context state. Lower drift for subsequent items means they blend more with the evolving context, creating temporal associations between nearby items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual drift (comment out if using above or stable drift)\n",
    "B_encD = np.array([1, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Matrix\n",
    "\n",
    "Defines pre-existing semantic associations between items:\n",
    "\n",
    "- **Identity matrix structure**: Each item has activation of 1.0 to itself, 0 to all others\n",
    "- This represents **orthogonal** items with no semantic similarity\n",
    "\n",
    "**Interpretation**: In this simple version, items have no inherent semantic relationships. The semantic route will primarily help retrieve items based on their direct activation rather than meaning-based associations. For more realistic simulations, this could be replaced with a structured similarity matrix based on word associations, categories, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create \"semantic\" matrix\n",
    "# each item has an activation of 1 (and to no other units)\n",
    "sem_mat = np.eye(len(pres_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Parameters (Polyn, Norman & Kahana, 2009)\n",
    "\n",
    "Core model parameters calibrated to fit human free recall data:\n",
    "\n",
    "## Network Architecture\n",
    "- **gamma_fc (0.581)**: Strength of pre-existing feature-context associations\n",
    "- **eye_fc, eye_cf**: Initialize connection matrices\n",
    "\n",
    "## Encoding Parameters\n",
    "- **B_enc (0.745)**: Standard context integration rate during study\n",
    "- **lrate_fc_enc**: Learning rate for feature→context connections\n",
    "- **lrate_cf_enc**: Learning rate for context→feature connections\n",
    "\n",
    "## Retrieval Parameters\n",
    "- **B_rec (0.36)**: Context integration during recall (slower than encoding)\n",
    "- **lrate_fc_rec, lrate_cf_rec (0)**: No new learning during recall\n",
    "\n",
    "## Decision Competition\n",
    "- **thresh (1)**: Activation threshold for successful recall\n",
    "- **L (0.375)**: Lateral inhibition between competing items\n",
    "- **K (0.091)**: Decay rate of accumulator activation\n",
    "- **eta (0.3699)**: Noise in the decision process\n",
    "- **tau (413 ms)**: Time constant for accumulation\n",
    "\n",
    "These parameters create a competitive retrieval process where items race to threshold, with noise and inhibition producing realistic recall dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET PARAMETERS\n",
    "\n",
    "# for creating the network\n",
    "gamma_fc = 0.581  # relative strength of pre-existing associations on connections feature-context\n",
    "eye_fc = 1 - gamma_fc  # if items are rep as orthonormal vectors, identity matrix (\"eye\")\n",
    "eye_cf = 0\n",
    "\n",
    "# during encoding\n",
    "B_enc = 0.745  # vector of context integration rate at encoding, dynamic alternative above\n",
    "lrate_fc_enc = gamma_fc  # feature-to-context during encoding\n",
    "lrate_cf_enc = 1  # context-to-feature during encoding\n",
    "\n",
    "# during recall\n",
    "B_rec = 0.36  # vector of context integration at recall\n",
    "lrate_fc_rec = 0  # feature-to-context during recall\n",
    "lrate_cf_rec = 0  # context-to-feature during recall\n",
    "thresh = 1  # threshold for an accumulating element to win the decision competition (fixed at 1)\n",
    "rec_time = 90000  # max recall process (interpreted as 90 seconds)\n",
    "dt = 100  # time constant on decision process\n",
    "L = 0.375  # lateral inhibition between units in decision competition\n",
    "K = 0.091  # decay rate for the accumulating elements in decision competition\n",
    "eta = 0.3699  # standard deviation of gaussian noise term in decision competition\n",
    "tau = 413  # time constant in decision competition\n",
    "\n",
    "n_sims = 1000  # number of simulations\n",
    "recall_sims = np.zeros((len(pres_indices), n_sims))\n",
    "times_sims = np.zeros((len(pres_indices), n_sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Run\n",
    "\n",
    "Main simulation loop implementing the CMR model's encoding and retrieval phases.\n",
    "\n",
    "## Overall Structure\n",
    "For each simulation:\n",
    "1. **Initialize network**: Create feature and context layers, connection weights\n",
    "2. **Encoding phase**: Present items sequentially, update context and associations\n",
    "3. **Retrieval phase**: Use context cues to retrieve items via competitive accumulation\n",
    "\n",
    "## Encoding Phase Logic\n",
    "For each presented item:\n",
    "1. Activate the item's feature representation\n",
    "2. Calculate context input from feature layer (via learned associations)\n",
    "3. Update context using drift equation: `c_new = ρ·c_old + β·c_in`\n",
    "   - **ρ (rho)**: Ensures context vector stays normalized\n",
    "   - **β (beta)**: Controls integration rate (how much context changes)\n",
    "4. Learn associations between active features and current context\n",
    "\n",
    "**Key insight**: Items encoded in similar contexts will be more likely to cue each other during recall.\n",
    "\n",
    "## Retrieval Phase Logic\n",
    "Iterative process until time runs out:\n",
    "1. Use current context to activate features (via episodic + semantic routes)\n",
    "2. Run accumulator race:\n",
    "   - Each item accumulates activation based on its cue strength\n",
    "   - Lateral inhibition suppresses competitors\n",
    "   - Noise creates variability\n",
    "   - Decay prevents runaway activation\n",
    "3. When an item crosses threshold:\n",
    "   - Record the recall\n",
    "   - Mark item as retrieved (prevent repetitions)\n",
    "   - Use retrieved item to update context\n",
    "   - Continue with new context state\n",
    "\n",
    "**Key insight**: Each recall changes context, which determines what gets recalled next - creating temporal contiguity effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sims in range(n_sims):\n",
    "    \n",
    "    # NETWORK\n",
    "    \n",
    "    # initialize the features and context layers\n",
    "    net_f = np.zeros((len(pres_indices), 1))\n",
    "    net_c = np.zeros((len(pres_indices), 1))\n",
    "    \n",
    "    # learning rate matrices\n",
    "    net_lrate_fc = np.zeros((len(pres_indices), len(pres_indices)))\n",
    "    net_lrate_cf = np.zeros((len(pres_indices), len(pres_indices)))\n",
    "    \n",
    "    # the lrate matrices\n",
    "    net_lrate_fc_enc = np.full((len(pres_indices), len(pres_indices)), lrate_fc_enc)\n",
    "    net_lrate_cf_enc = np.full((len(pres_indices), len(pres_indices)), lrate_cf_enc)\n",
    "    net_lrate_fc_rec = np.full((len(pres_indices), len(pres_indices)), lrate_fc_rec)\n",
    "    net_lrate_cf_rec = np.full((len(pres_indices), len(pres_indices)), lrate_cf_rec)\n",
    "    \n",
    "    net_w_fc = np.eye(len(net_c)) * eye_fc  # m_fc eye() creates identity matrices\n",
    "    net_w_cf = np.eye(len(net_f)) * eye_cf  # m_cf zero\n",
    "    net_weights = np.zeros((len(pres_indices), len(pres_indices)))\n",
    "    \n",
    "    # ENCODING\n",
    "    \n",
    "    net_idx = np.arange(len(pres_indices))\n",
    "    \n",
    "    for item in range(len(pres_indices)):\n",
    "        \n",
    "        # present item\n",
    "        feature_idx = pres_indices[item] - 1  # Convert to 0-indexed\n",
    "        \n",
    "        # activates the indexed feature (each item activates one element)\n",
    "        net_f = np.zeros((len(pres_indices), 1))\n",
    "        net_f[feature_idx] = 1\n",
    "        \n",
    "        # update context representations\n",
    "        net_c_in = net_w_fc @ net_f\n",
    "        \n",
    "        # normalize vector\n",
    "        vec = net_c_in\n",
    "        denom_vec = np.sqrt(vec.T @ vec)[0, 0]\n",
    "        norm_vec = vec / denom_vec\n",
    "        net_c_in = norm_vec\n",
    "        \n",
    "        # advance context\n",
    "        c_in = net_c_in\n",
    "        c = net_c\n",
    "        \n",
    "        # set dynamic or stable drift\n",
    "        B = B_encD[item]  # beta at encoding for dynamic\n",
    "        # B = B_enc  # beta at encoding if stable\n",
    "        \n",
    "        dot_product = (c.T @ c_in)[0, 0]\n",
    "        rho = np.sqrt(1 + (B**2) * ((dot_product**2) - 1)) - B * dot_product\n",
    "        updated_c = rho * c + B * c_in\n",
    "        net_c = updated_c\n",
    "        \n",
    "        # determine current learning rate\n",
    "        lrate_fc = net_lrate_fc_enc\n",
    "        lrate_cf = net_lrate_cf_enc\n",
    "        \n",
    "        # update weights\n",
    "        \n",
    "        # w_fc\n",
    "        delta = (net_c @ net_f.T) * lrate_fc\n",
    "        net_w_fc = net_w_fc + delta\n",
    "        \n",
    "        # w_cf\n",
    "        delta = (net_f @ net_c.T) * lrate_cf\n",
    "        net_w_cf = net_w_cf + delta\n",
    "    \n",
    "    # RECALL\n",
    "    \n",
    "    # set up\n",
    "    recalls = np.zeros((len(pres_indices), 1))\n",
    "    times = np.zeros((len(pres_indices), 1))\n",
    "    \n",
    "    rec_time_local = 90000\n",
    "    time_passed = 0\n",
    "    recall_count = 0\n",
    "    \n",
    "    retrieved = np.zeros((len(pres_indices), 1), dtype=bool)\n",
    "    thresholds = np.ones((len(pres_indices), 1))\n",
    "    \n",
    "    # semantic + episodic routes\n",
    "    net_weights = episodic_weight * net_w_cf + sem_weight * sem_mat\n",
    "    \n",
    "    # GO!!!\n",
    "    \n",
    "    while time_passed < rec_time_local:\n",
    "        \n",
    "        # input to the feature layer, from last context cue\n",
    "        f_in = net_weights @ net_c\n",
    "        \n",
    "        # set max number of cycles\n",
    "        max_cycles = int((rec_time_local - time_passed) / dt)\n",
    "        \n",
    "        # for noise error standard deviation\n",
    "        dt_tau = dt / tau\n",
    "        sq_dt_tau = np.sqrt(dt_tau)\n",
    "        \n",
    "        # noise matrix\n",
    "        noise = np.random.normal(0, eta * sq_dt_tau, (len(pres_indices), max_cycles))\n",
    "        eyeI = ~np.eye(len(pres_indices), dtype=bool)\n",
    "        lmat = eyeI.astype(float) * L\n",
    "        \n",
    "        ncycles = noise.shape[1]\n",
    "        inds = np.arange(len(pres_indices))\n",
    "        \n",
    "        crossed = 0\n",
    "        \n",
    "        x = np.zeros((len(pres_indices), 1))\n",
    "        \n",
    "        K_array = np.ones((len(pres_indices), 1)) * K\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        # ACCUMULATORS CYCLING\n",
    "        while i < ncycles and crossed == 0:\n",
    "            \n",
    "            # the lateral inhibition felt by each unit\n",
    "            lx = lmat @ x\n",
    "            \n",
    "            # the activity leaking from each unit\n",
    "            kx = K_array * x\n",
    "            \n",
    "            # change in each accumulator\n",
    "            x = x + ((f_in - kx - lx) * dt_tau + noise[:, i:i+1])\n",
    "            x[x < 0] = 0\n",
    "            \n",
    "            # reset retrieved values, allow them to compete but prevent from accumulating\n",
    "            reset_these = retrieved & (x >= thresholds)\n",
    "            x[reset_these] = 0.95 * thresholds[reset_these]\n",
    "            \n",
    "            # retrieved items cannot be repeated\n",
    "            retrievable = ~retrieved\n",
    "            \n",
    "            # determine whether any items have crossed thresholds\n",
    "            crossed = 0\n",
    "            if np.any(x[retrievable] >= thresholds[retrievable]):\n",
    "                crossed = 1\n",
    "                temp_win = x[retrievable] >= thresholds[retrievable]\n",
    "                temp_ind = inds[retrievable.flatten()]\n",
    "                winners = temp_ind[temp_win.flatten()]\n",
    "                \n",
    "                # if there is a tie, random tiebreak\n",
    "                if len(winners) > 1:\n",
    "                    winners = np.array([np.random.choice(winners)])\n",
    "                \n",
    "                winner_position = np.where(pres_indices - 1 == winners[0])[0][0]\n",
    "            \n",
    "            i = i + 1\n",
    "        \n",
    "        # calculate the amount of elapsed time\n",
    "        time = i * dt\n",
    "        \n",
    "        time_passed = time_passed + time\n",
    "        \n",
    "        # reactivate item if there has been a retrieval\n",
    "        if crossed == 1:\n",
    "            \n",
    "            # activate the retrieved feature\n",
    "            net_f = np.zeros((len(pres_indices), 1))\n",
    "            net_f[winners[0]] = 1\n",
    "            \n",
    "            # update context representations\n",
    "            net_c_in = net_w_fc @ net_f\n",
    "            \n",
    "            # normalize vector\n",
    "            vec = net_c_in\n",
    "            denom_vec = np.sqrt(vec.T @ vec)[0, 0]\n",
    "            norm_vec = vec / denom_vec\n",
    "            net_c_in = norm_vec\n",
    "            \n",
    "            # advance context\n",
    "            c_in = net_c_in\n",
    "            c = net_c\n",
    "            B = B_rec  # beta at retrieval\n",
    "            \n",
    "            dot_product = (c.T @ c_in)[0, 0]\n",
    "            rho = np.sqrt(1 + (B**2) * ((dot_product**2) - 1)) - B * dot_product\n",
    "            updated_c = rho * c + B * c_in\n",
    "            net_c = updated_c\n",
    "            \n",
    "            # determine current learning rate\n",
    "            lrate_fc = net_lrate_fc_rec\n",
    "            lrate_cf = net_lrate_cf_rec\n",
    "            \n",
    "            # w_fc\n",
    "            delta = (net_c @ net_f.T) * lrate_fc\n",
    "            net_w_fc = net_w_fc + delta\n",
    "            \n",
    "            # w_cf\n",
    "            delta = (net_f @ net_c.T) * lrate_cf\n",
    "            net_w_cf = net_w_cf + delta\n",
    "            \n",
    "            # record data\n",
    "            recall_count = recall_count + 1\n",
    "            recalls[recall_count - 1, 0] = winner_position + 1  # Convert back to 1-indexed\n",
    "            times[recall_count - 1, 0] = time_passed\n",
    "            \n",
    "            # update retrieved vector\n",
    "            retrieved[winners[0]] = True\n",
    "    \n",
    "    recall_sims[:, sims] = recalls.flatten()\n",
    "    times_sims[:, sims] = times.flatten()\n",
    "\n",
    "print(f\"Model run complete. Simulated {n_sims} trials.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Position Curve\n",
    "\n",
    "Analyzes recall probability as a function of an item's position in the study list.\n",
    "\n",
    "## Calculation Logic\n",
    "For each serial position (1-10):\n",
    "- Count how many times items from that position were recalled across all simulations\n",
    "- Divide by total number of simulations to get recall probability\n",
    "\n",
    "## Expected Pattern\n",
    "Classic serial position curve shows:\n",
    "- **Primacy effect**: Higher recall for early items (positions 1-3)\n",
    "  - Caused by high initial context drift creating distinct temporal context\n",
    "- **Recency effect**: Higher recall for recent items (positions 8-10)\n",
    "  - Caused by end-of-list context still being active during recall\n",
    "- **Middle items**: Lower recall for mid-list positions\n",
    "  - These items compete with many similar contexts\n",
    "\n",
    "## Interpretation\n",
    "The curve shape reveals how temporal context affects memory strength. Items encoded in unique contexts (beginning/end) are easier to retrieve than items in crowded temporal neighborhoods (middle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the total proportion of recall given the serial position\n",
    "position = pd.DataFrame({'position': np.arange(1, len(pres_indices) + 1)})\n",
    "\n",
    "numSums = np.zeros(len(pres_indices))\n",
    "\n",
    "for numSum in range(len(numSums)):\n",
    "    numSums[numSum] = np.sum(recall_sims == (numSum + 1))\n",
    "\n",
    "recall = numSums / n_sims\n",
    "\n",
    "prop_recall = pd.DataFrame({\n",
    "    'position': position['position'],\n",
    "    'recall': recall\n",
    "})\n",
    "\n",
    "print(prop_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial Position Curve Visualization\n",
    "\n",
    "This plot shows the probability of recalling an item as a function of its study position. The shape reveals fundamental memory processes:\n",
    "\n",
    "- **Rising curve**: Indicates strong recency effect (later items better recalled)\n",
    "- **U-shape**: Would indicate both primacy and recency\n",
    "- **Flat curve**: Would suggest position-independent recall\n",
    "\n",
    "With high first-item drift (B=1.0) and moderate subsequent drift (B=0.65), we expect strong recency and possible primacy enhancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot recall success as a function of serial position\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(prop_recall['position'], prop_recall['recall'], 'o-', linewidth=2, markersize=8)\n",
    "plt.xlabel('serial position', fontsize=15)\n",
    "plt.ylabel('probability of recall', fontsize=15)\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Recall Probability\n",
    "\n",
    "Analyzes which items are most likely to be recalled first when retrieval begins.\n",
    "\n",
    "## Calculation Logic\n",
    "- Extract the first recalled item from each simulation\n",
    "- Count frequency of each position being recalled first\n",
    "- Convert to proportions\n",
    "\n",
    "## Theoretical Predictions\n",
    "First recall is strongly influenced by:\n",
    "1. **Recency**: Recent items have highest context match with end-of-list state\n",
    "2. **Primacy**: With high initial drift, first item may have unique retrieval advantage\n",
    "3. **Semantic strength**: Items with strong semantic cues may be recalled first\n",
    "\n",
    "## Interpretation\n",
    "Typically shows extreme recency bias - the last item is most likely to be recalled first because recall begins from the end-of-list context state. The probability of first recall (PFR) curve is often steeper than the overall serial position curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the proportion of \"first recall\" items as a function of serial position\n",
    "first_recall = recall_sims[0, :]\n",
    "first_recall = first_recall[first_recall > 0]  # Filter out zeros\n",
    "\n",
    "# Count frequencies\n",
    "unique, counts = np.unique(first_recall, return_counts=True)\n",
    "first_recall_table = pd.DataFrame({\n",
    "    'position': unique.astype(int),\n",
    "    'freq': counts,\n",
    "    'prop': counts / n_sims\n",
    "})\n",
    "\n",
    "print(first_recall_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Recall Probability Visualization\n",
    "\n",
    "Shows the likelihood of each position being the first item recalled. This analysis reveals:\n",
    "\n",
    "- **Peak position**: Identifies which items have strongest initial retrieval strength\n",
    "- **Slope steepness**: Indicates how strongly position affects immediate accessibility\n",
    "- **Distribution spread**: Shows whether recall initiates from diverse or concentrated positions\n",
    "\n",
    "In free recall, the last few items typically dominate first recalls due to context matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first recall proportion as a function of serial position\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(first_recall_table['position'], first_recall_table['prop'], 'o-', linewidth=2, markersize=8)\n",
    "plt.xlabel('serial position', fontsize=15)\n",
    "plt.ylabel('probability of first recall', fontsize=15)\n",
    "plt.ylim(0, 0.8)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Response Probabilities (CRP)\n",
    "\n",
    "Analyzes the **temporal contiguity effect**: the tendency to recall items that were studied near each other in time.\n",
    "\n",
    "## Calculation Logic\n",
    "\n",
    "### Step 1: Calculate Actual Transitions\n",
    "For each recall sequence, compute the \"lag\" between consecutive recalls:\n",
    "- Lag = (position of item N+1) - (position of item N)\n",
    "- Example: If positions 5→7 are recalled consecutively, lag = +2\n",
    "- Example: If positions 8→6 are recalled consecutively, lag = -2\n",
    "\n",
    "### Step 2: Calculate Possible Transitions\n",
    "At each recall, determine which items could still be recalled:\n",
    "- Exclude already-recalled items\n",
    "- Calculate all possible lags from current position\n",
    "\n",
    "### Step 3: Compute CRP\n",
    "For each lag value:\n",
    "- CRP(lag) = P(transition to lag | lag is available)\n",
    "- CRP(lag) = (# actual transitions of lag) / (# times lag was available)\n",
    "\n",
    "## Expected Pattern\n",
    "- **Peak at lag ±1**: Strongest tendency to recall adjacent items\n",
    "- **Asymmetry**: Often stronger forward (positive lag) than backward\n",
    "- **Decline with distance**: Probability decreases for distant items\n",
    "- **Gap at lag 0**: Can't recall the same item twice\n",
    "\n",
    "## Interpretation\n",
    "CRP reveals temporal organization in memory. High values near lag ±1 show that retrieving an item reinstates its encoding context, which cues nearby items. This is the signature of context-based retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poss_outcomes = np.arange(-9, 10)\n",
    "poss_outcomes = np.delete(poss_outcomes, 9)  # Remove the element at index 9 (value 0)\n",
    "\n",
    "# create matrix of actual transitions\n",
    "trans_sims = np.zeros((len(pres_indices), n_sims))\n",
    "\n",
    "for subj in range(n_sims):\n",
    "    currentSub = recall_sims[:, subj]\n",
    "    \n",
    "    for trial in range(9):\n",
    "        if currentSub[trial + 1] > 0:\n",
    "            trans_sims[trial, subj] = currentSub[trial + 1] - currentSub[trial]\n",
    "        else:\n",
    "            trans_sims[trial, subj] = 0\n",
    "\n",
    "# create matrix of all possible transitions\n",
    "possTransFrame = []\n",
    "\n",
    "for subj in range(n_sims):\n",
    "    currentSub = recall_sims[:, subj]\n",
    "    possTrans_sims = np.zeros((10, 9))\n",
    "    \n",
    "    for trial in range(9):\n",
    "        if currentSub[trial + 1] > 0:\n",
    "            currentTrial = currentSub[trial]\n",
    "            itemTally = currentSub[0:trial + 1]\n",
    "            possPositions = pres_indices[~np.isin(pres_indices, itemTally)]\n",
    "            possTransitions = possPositions - currentTrial\n",
    "            \n",
    "            for poss in range(len(possTransitions)):\n",
    "                possTrans_sims[trial, poss] = possTransitions[poss]\n",
    "    \n",
    "    possTransFrame.append(possTrans_sims)\n",
    "\n",
    "possTransFrame = np.vstack(possTransFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRP Data Processing\n",
    "\n",
    "This cell computes the conditional response probability for each lag:\n",
    "\n",
    "1. **Filter transitions**: Focus on lags within ±5 positions (most informative range)\n",
    "2. **Calculate probabilities**: Divide actual transitions by possible transitions\n",
    "3. **Result interpretation**:\n",
    "   - High CRP values: Strong tendency for that lag\n",
    "   - Low CRP values: Weak tendency or random transitions\n",
    "   - Relative heights: Compare forward vs. backward recall patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CRP\n",
    "actual_transitions = trans_sims[trans_sims != 0]\n",
    "possible_transitions = possTransFrame[possTransFrame != 0]\n",
    "\n",
    "# Count frequencies\n",
    "tab_a_t_unique, tab_a_t_counts = np.unique(actual_transitions, return_counts=True)\n",
    "tab_p_t_unique, tab_p_t_counts = np.unique(possible_transitions, return_counts=True)\n",
    "\n",
    "tab_a_t = pd.DataFrame({\n",
    "    'actual_transitions': tab_a_t_unique,\n",
    "    'Freq': tab_a_t_counts\n",
    "})\n",
    "\n",
    "tab_p_t = pd.DataFrame({\n",
    "    'possible_transitions': tab_p_t_unique,\n",
    "    'Freq': tab_p_t_counts\n",
    "})\n",
    "\n",
    "# Filter\n",
    "tab_a_t = tab_a_t[(tab_a_t['actual_transitions'] < 6) & (tab_a_t['actual_transitions'] > -6)]\n",
    "tab_p_t = tab_p_t[(tab_p_t['possible_transitions'] < 6) & (tab_p_t['possible_transitions'] > -6)]\n",
    "\n",
    "# Calculate CRP\n",
    "crp = tab_a_t['Freq'].values / tab_p_t['Freq'].values\n",
    "\n",
    "crps = pd.DataFrame({\n",
    "    'transitions': tab_a_t['actual_transitions'].values,\n",
    "    'crp': crp\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRP Visualization\n",
    "\n",
    "The lag-CRP curve is a key signature of temporal context effects in memory:\n",
    "\n",
    "**Key Features to Observe**:\n",
    "- **Central peak**: Should be highest near lag ±1 (adjacent items)\n",
    "- **Contiguity gradient**: Probability decreases with increasing lag distance\n",
    "- **Forward asymmetry**: Often stronger for positive lags (forward in time)\n",
    "- **White gap at lag 0**: Represents the discontinuity (can't recall same item)\n",
    "\n",
    "**What this reveals**: The peaked shape demonstrates that context serves as an effective retrieval cue - items studied in similar temporal contexts are recalled together. The asymmetry (if present) suggests forward-going associations are stronger than backward associations during encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot CRP\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(crps['transitions'], crps['crp'], 'o-', linewidth=2, markersize=8)\n",
    "\n",
    "# Add white segments to mask the gap at lag 0 (between -1 and 1)\n",
    "mask_indices = (crps['transitions'] == -1) | (crps['transitions'] == 1)\n",
    "if mask_indices.sum() == 2:\n",
    "    idx_neg1 = crps[crps['transitions'] == -1].index[0]\n",
    "    idx_pos1 = crps[crps['transitions'] == 1].index[0]\n",
    "    plt.plot([-1, 1], [crps.loc[idx_neg1, 'crp'], crps.loc[idx_pos1, 'crp']], \n",
    "             'w-', linewidth=3, zorder=10)\n",
    "\n",
    "plt.xlabel('lag', fontsize=15)\n",
    "plt.ylabel('conditional response probability', fontsize=15)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=13)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Matrices\n",
    "\n",
    "Visualizes the learned associations between items and temporal context after encoding.\n",
    "\n",
    "## Two Association Matrices\n",
    "\n",
    "### Feature-to-Context (M^FC)\n",
    "- **Rows**: Context elements\n",
    "- **Columns**: Item positions (serial order)\n",
    "- **Values**: How strongly each item activates each context element\n",
    "- **Interpretation**: Shows what context was active when each item was encoded\n",
    "\n",
    "### Context-to-Feature (M^CF)\n",
    "- **Rows**: Item positions\n",
    "- **Columns**: Context elements  \n",
    "- **Values**: How strongly each context element retrieves each item\n",
    "- **Interpretation**: Shows which items are cued by each context state\n",
    "\n",
    "## Expected Patterns\n",
    "\n",
    "**Diagonal structure**: Items are most strongly associated with their encoding context\n",
    "\n",
    "**Gradient/smearing**: Due to context drift, nearby items share similar contexts\n",
    "- More smearing = more context overlap = stronger temporal associations\n",
    "- Less smearing = more distinct contexts = weaker temporal associations\n",
    "\n",
    "**First item distinctiveness**: High initial drift (B=1.0) should create unique first-item pattern\n",
    "\n",
    "## Functional Significance\n",
    "These matrices implement the episodic memory route. During retrieval, the current context state activates items via M^CF, and retrieved items update context via M^FC, creating a feedback loop that drives sequential recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-organize weight matrices for plotting (so as to view them by serial position)\n",
    "net_w_fc_inorder = net_w_fc[:, pres_indices - 1]  # Convert to 0-indexed\n",
    "net_w_cf_inorder = net_w_cf[pres_indices - 1, :]  # Convert to 0-indexed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Matrix Visualization\n",
    "\n",
    "These heatmaps reveal the structure of learned episodic associations:\n",
    "\n",
    "**Left plot (Feature→Context)**:\n",
    "- Warm colors (orange/red): Strong activation of context by item\n",
    "- Pattern reveals temporal context evolution during encoding\n",
    "- Examine: Is there a diagonal? How much do patterns overlap?\n",
    "\n",
    "**Right plot (Context→Feature)**:\n",
    "- Warm colors (red): Strong retrieval cue strength\n",
    "- Pattern reveals which items are accessible from each context\n",
    "- Examine: Can you see temporal gradients? First/last item distinctiveness?\n",
    "\n",
    "Together, these matrices encode the episodic memory trace that drives context-based retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up weight matrices plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Feature to context weight matrix\n",
    "im1 = axes[0].imshow(net_w_fc_inorder, cmap='YlOrRd', aspect='auto')\n",
    "axes[0].set_title('feature to context weight matrix', fontsize=16)\n",
    "axes[0].set_xlabel('serial position', fontsize=14)\n",
    "axes[0].set_ylabel('', fontsize=14)\n",
    "axes[0].set_xticks(np.arange(len(pres_indices)))\n",
    "axes[0].set_xticklabels(np.arange(1, len(pres_indices) + 1))\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Context to feature weight matrix\n",
    "im2 = axes[1].imshow(net_w_cf_inorder.T, cmap='Reds', aspect='auto')\n",
    "axes[1].set_title('context to feature weight matrix', fontsize=16)\n",
    "axes[1].set_xlabel('serial position', fontsize=14)\n",
    "axes[1].set_ylabel('', fontsize=14)\n",
    "axes[1].set_xticks(np.arange(len(pres_indices)))\n",
    "axes[1].set_xticklabels(np.arange(1, len(pres_indices) + 1))\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrices\n",
    "\n",
    "Analyzes the similarity structure of learned representations by computing correlations between columns (items) of the weight matrices.\n",
    "\n",
    "## What Correlations Reveal\n",
    "\n",
    "### Feature-to-Context Correlations\n",
    "- Correlates context patterns activated by different items\n",
    "- **High correlation**: Two items activated similar contexts (encoded nearby in time)\n",
    "- **Low correlation**: Two items activated distinct contexts (encoded far apart)\n",
    "- **Pattern**: Should show temporal gradient - higher correlation for items closer in study order\n",
    "\n",
    "### Context-to-Feature Correlations  \n",
    "- Correlates the retrieval strength patterns across context states\n",
    "- **High correlation**: Two items are similarly cued by the same contexts\n",
    "- **Low correlation**: Two items are cued by different contexts\n",
    "- **Pattern**: Reflects temporal organization of memory accessibility\n",
    "\n",
    "## Expected Structure\n",
    "\n",
    "**Banded diagonal**: Strongest correlations near the diagonal (adjacent items)\n",
    "\n",
    "**Gradient decay**: Correlation decreases with increasing temporal distance\n",
    "\n",
    "**Primacy/recency islands**: Possible distinct correlation structures at list boundaries\n",
    "\n",
    "## Functional Interpretation\n",
    "These correlation patterns quantify the temporal organization of episodic memory. The gradient structure directly predicts the temporal contiguity effect in recall - items with high context correlation are likely to be recalled together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up correlation plots\n",
    "corr_fc = np.corrcoef(net_w_fc_inorder.T)\n",
    "corr_cf = np.corrcoef(net_w_cf_inorder)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Feature to context correlation matrix\n",
    "im1 = axes[0].imshow(corr_fc, cmap='YlOrRd', aspect='auto', vmin=-1, vmax=1)\n",
    "axes[0].set_title('feature to context weight matrix', fontsize=16)\n",
    "axes[0].set_xlabel('serial position', fontsize=14)\n",
    "axes[0].set_ylabel('', fontsize=14)\n",
    "axes[0].set_xticks(np.arange(len(pres_indices)))\n",
    "axes[0].set_xticklabels(np.arange(1, len(pres_indices) + 1))\n",
    "axes[0].set_yticks(np.arange(len(pres_indices)))\n",
    "axes[0].set_yticklabels(np.arange(1, len(pres_indices) + 1))\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Context to feature correlation matrix\n",
    "im2 = axes[1].imshow(corr_cf, cmap='YlOrRd', aspect='auto', vmin=-1, vmax=1)\n",
    "axes[1].set_title('context to feature weight matrix', fontsize=16)\n",
    "axes[1].set_xlabel('serial position', fontsize=14)\n",
    "axes[1].set_ylabel('', fontsize=14)\n",
    "axes[1].set_xticks(np.arange(len(pres_indices)))\n",
    "axes[1].set_xticklabels(np.arange(1, len(pres_indices) + 1))\n",
    "axes[1].set_yticks(np.arange(len(pres_indices)))\n",
    "axes[1].set_yticklabels(np.arange(1, len(pres_indices) + 1))\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Guide for Correlation Matrices\n",
    "\n",
    "**Reading the plots**:\n",
    "- **Diagonal (perfect correlation)**: Each item correlates perfectly with itself\n",
    "- **Near-diagonal bands**: Show temporal neighborhood structure\n",
    "- **Off-diagonal patterns**: Reveal long-range associations\n",
    "- **Color intensity**: Strength of representational similarity\n",
    "\n",
    "**What to look for**:\n",
    "1. **Width of diagonal band**: Indicates temporal resolution of context\n",
    "   - Narrow band = sharp temporal discrimination\n",
    "   - Wide band = gradual context change\n",
    "\n",
    "2. **Asymmetries**: Might reveal forward/backward association differences\n",
    "\n",
    "3. **Clustering**: Groups of items with similar correlation profiles\n",
    "\n",
    "These patterns bridge the gap between neural representations and behavioral recall patterns, showing how temporal context similarity translates to recall transitions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
